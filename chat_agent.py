"""
The ChatAgent class facilitates communication with the LLM and various tools.
"""

from langchain.agents import initialize_agent, load_tools
from langchain.memory import ChatMessageHistory
from langchain_community.llms import HuggingFaceEndpoint
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import BaseMessage
from pyowm.commons import exceptions

class ChatAgent:
    """
    This class enables interaction with an LLM and the OpenWeatherMap service.
    """

    def __init__(self):
        """
        Initializes the ChatAgent by loading the LLM and setting up the weather forecast tool.
        Configures the agent to maintain chat history and respond to queries.
        """
        #Need to Update teh Hugging Face Token here"
        import os
        os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hugging_face_token"

        #Need to update the weather report api
        sec_key = "weather_api_key"
        repo_id = "mistralai/Mistral-7B-Instruct-v0.2"

        # Load the LLM
        llm = HuggingFaceEndpoint(repo_id=repo_id, max_length=128, temperature=0.01, token=sec_key)

        os.environ["OPENWEATHERMAP_API_KEY"] = sec_key

        # Load the weather query tool from OpenWeatherMap
        tools = load_tools(["openweathermap-api"], llm)

        print(tools)

        # Set up an agent chain
        agent_chain = initialize_agent(tools=tools, llm=llm, verbose=True, handle_parsing_errors=True, max_iterations=4)

        # Define a prompt to manage chat history
        prompt = ChatPromptTemplate.from_messages([MessagesPlaceholder(variable_name="messages")])

        self.__agent_chain = prompt | agent_chain

    @property
    def chat_history(self) -> ChatMessageHistory:
        """
        Access the chat history for the current session.

        Returns
        -------
        ChatMessageHistory
            The chat history of the current session.
        """
        if not hasattr(self, '_chat_history'):
            self._chat_history = ChatMessageHistory()
        return self._chat_history

    def respond(self, user_message: str) -> str:
        """
        Generate a response to a user's message.

        Parameters
        ----------
        user_message : str
            The message from the user.

        Returns
        -------
        str
            The response generated by the agent.
        """
        # Add the user message to chat history
        self.chat_history.add_user_message(user_message)

        # Get the agent's response
        response = self.__agent_chain.invoke({"messages": self.chat_history.messages})

        # Add the response to chat history
        self.chat_history.add_ai_message(response)

        return response
